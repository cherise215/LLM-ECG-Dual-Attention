{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../..')\n",
    "from multi_modal_heart.model.ecg_net_attention import ECGEncoder,ECGAttentionAE\n",
    "from multi_modal_heart.model.ecg_net import ECGAE\n",
    "from multi_modal_heart.model.ecg_net import BenchmarkClassifier\n",
    "from multi_modal_heart.ECG.ecg_dataset import ECGDataset\n",
    "\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self,encoder,input_dim,num_classes=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        #### add classifier if use benchmark classifier\n",
    "        self.downsteam_net = BenchmarkClassifier(input_size=input_dim,hidden_size=128,output_size=num_classes)\n",
    "    def forward(self, x, mask):\n",
    "        latent_code = self.encoder.get_features_after_pooling(x,mask)\n",
    "        return self.downsteam_net(latent_code)\n",
    "    \n",
    "def print_result(probs,super_classes_labels, topk=1):\n",
    "    probs, label_indices = torch.topk(probs, topk)\n",
    "    probs = probs.tolist()\n",
    "    label_indices = label_indices.tolist()\n",
    "    for prob, idx in zip(probs, label_indices):\n",
    "        label = super_classes_labels[idx]\n",
    "        print(f'{label} ({idx}):', round(prob, 4))\n",
    "def calc_hamming_score(y_true, y_pred):\n",
    "    return (\n",
    "        (y_true & y_pred).sum(axis=1) / (y_true | y_pred).sum(axis=1)\n",
    "    ).mean()    \n",
    "# ecg_net = ECGAttentionAE(num_leads=12, time_steps=1024, z_dims=512, linear_out=512, downsample_factor=5, base_feature_dim=4,if_VAE=False,\n",
    "#                          use_attention_pool=False,no_linear_in_E=True, apply_lead_mask=False, no_time_attention=False)\n",
    "# classification_net = LitClassifier(encoder=ecg_net.encoder,input_dim=512,num_classes=5)\n",
    "# # checkpoint_path  =\"../../log_finetune/ECG_attention_512_raw_no_attention_pool_no_linear_abl_no_time_attention_ms_resnet/checkpoints/last-v3.ckpt\"\n",
    "# # checkpoint_path  =\"../../log_finetune/ECG_attention_512_raw_no_attention_pool_no_linear_ms_resnet_ECG2Text/checkpoints/last-v5.ckpt\"\n",
    "# checkpoint_path = \"../../log_finetune/ECG_attention_512_raw_no_attention_pool_no_linear_ms_resnet/checkpoints/last-v8.ckpt\"\n",
    "# print (torch.load(checkpoint_path)[\"state_dict\"].keys())\n",
    "# mm_checkpoint = torch.load(checkpoint_path)[\"state_dict\"]\n",
    "# encoder_params = {(\".\").join(key.split(\".\")[1:]):value for key, value in mm_checkpoint.items() if str(key).startswith(\"encoder\")}\n",
    "# classification_params = {(\".\").join(key.split(\".\")[1:]):value for key, value in mm_checkpoint.items() if str(key).startswith(\"downsteam_net\")}\n",
    "# classification_net.encoder.load_state_dict(encoder_params)\n",
    "# classification_net.downsteam_net.load_state_dict(classification_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from multi_modal_heart.model.ecg_net import ECGAE\n",
    "use_median_wave = True\n",
    "time_steps = 608\n",
    "ecg_net= ECGAE(encoder_type=\"resnet1d101\",in_channels=12,ECG_length=time_steps,decoder_type=\"ms_resnet\",\n",
    "                    embedding_dim=256,latent_code_dim=512,\n",
    "                    add_time=False,\n",
    "                    encoder_mha = False,\n",
    "                    apply_method=\"\",\n",
    "                    decoder_outdim=12)\n",
    "classification_net = LitClassifier(encoder=ecg_net.encoder,input_dim=512,num_classes=5)\n",
    "# resnet_checkpoint = '../../log_finetune/resnet1d101_512+benchmark_classifier_ms_resnet/checkpoints/epoch=23-val_auroc:benchmark_classifier/val_macro_auc=0.91.ckpt'\n",
    "resnet_checkpoint = \"/home/engs2522/project/multi-modal-heart/log_median_finetune/resnet1d101_512+benchmark_classifier_ms_resnet_ECG2Text/checkpoints/checkpoint_best_loss.ckpt\"\n",
    "checkpoint = torch.load(resnet_checkpoint)[\"state_dict\"]\n",
    "encoder_params = {(\".\").join(key.split(\".\")[1:]):value for key, value in checkpoint.items() if str(key).startswith(\"encoder\")}\n",
    "classification_params = {(\".\").join(key.split(\".\")[1:]):value for key, value in checkpoint.items() if str(key).startswith(\"downsteam_net\")}\n",
    "classification_net.encoder.load_state_dict(encoder_params)\n",
    "classification_net.downsteam_net.load_state_dict(classification_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_median_wave = False\n",
    "# # checkpoint_path = \"../../log_finetune/ECG_attention_512_raw_no_attention_pool_no_linear_ms_resnet/checkpoints/epoch=49-val_auroc:benchmark_classifier/val_macro_auc=0.90.ckpt\"\n",
    "checkpoint_path = \"../../log_median_finetune/ECG_attention_512_raw_no_attention_pool_no_linear_ms_resnet_ECG2Text/checkpoints/checkpoint_best_loss.ckpt\"\n",
    "# checkpoint_path = \"../../log_finetune/ECG_attention_512_raw_no_attention_pool_no_linear_ms_resnet/checkpoints/epoch=49-val_auroc:benchmark_classifier/val_macro_auc=0.90.ckpt\"\n",
    "\n",
    "use_median_wave = True\n",
    "time_steps = 608\n",
    "ecg_net = ECGAttentionAE(num_leads=12, time_steps=time_steps, z_dims=512, linear_out=512, downsample_factor=5, base_feature_dim=4,if_VAE=False,use_attention_pool=False,\n",
    "                         no_linear_in_E=True, apply_lead_mask=False)\n",
    "classification_net = LitClassifier(encoder=ecg_net.encoder,input_dim=512,num_classes=5)\n",
    "\n",
    "print (torch.load(checkpoint_path)[\"state_dict\"].keys())\n",
    "mm_checkpoint = torch.load(checkpoint_path)[\"state_dict\"]\n",
    "encoder_params = {(\".\").join(key.split(\".\")[1:]):value for key, value in mm_checkpoint.items() if str(key).startswith(\"encoder\")}\n",
    "classification_params = {(\".\").join(key.split(\".\")[1:]):value for key, value in mm_checkpoint.items() if str(key).startswith(\"downsteam_net\")}\n",
    "classification_net.encoder.load_state_dict(encoder_params)\n",
    "classification_net.downsteam_net.load_state_dict(classification_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load MI data from UKB\n",
    "from scipy.stats import zscore\n",
    "\n",
    "mi_data_path = \"/home/engs2522/project/multi-modal-heart/multi_modal_heart/toolkits/ukb/non_imaging_information/MI/batched_ecg_median_wave.npy\"\n",
    "\n",
    "test_data = np.load(mi_data_path)\n",
    "## zero mean and unit variance\n",
    "test_data = zscore(test_data,axis=2)\n",
    "test_data = np.nan_to_num(test_data)\n",
    "\n",
    "## pad the data to 1024\n",
    "test_data = np.pad(test_data,((0,0),(0,0),((time_steps-test_data.shape[2])//2,(time_steps-test_data.shape[2])//2)),\"constant\",constant_values=0)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tensor = torch.from_numpy(test_data).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get model prediction\n",
    "classification_net.eval()\n",
    "classification_net.freeze()\n",
    "with torch.no_grad():\n",
    "    classification_net.cuda()\n",
    "    probs = classification_net(test_data_tensor,None)\n",
    "    probs = torch.sigmoid(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use threshold to get prediction\n",
    "predict_labels=probs>=0.5\n",
    "print(predict_labels.shape)\n",
    "## MI class is the second one.\n",
    "predict_labels = predict_labels[:,1]\n",
    "print(predict_labels.shape)\n",
    "print(torch.sum(predict_labels))\n",
    "print('acc:',predict_labels.sum()/len(predict_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate MI data\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "result = mlb.fit_transform([[\"NORM\", \"MI\", \"HYP\",\"STTC\",\"CD\"]])\n",
    "# print (binarizer.classes_)\n",
    "mlb.classes_ = np.array([\"NORM\", \"MI\", \"HYP\",\"STTC\",\"CD\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_net = ECGAttentionAE(num_leads=12, time_steps=1024, z_dims=512, linear_out=512, downsample_factor=5, base_feature_dim=4,if_VAE=False,use_attention_pool=False,\n",
    "                         no_linear_in_E=True, apply_lead_mask=False)\n",
    "classification_net = LitClassifier(encoder=ecg_net.encoder,input_dim=512,num_classes=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
